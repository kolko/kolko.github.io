<html><body><script src="/showdown.min.js"></script><textarea id="sourceTA" style="display: none">
### портировано из http://opencarbon.ru/участники:коля:читательский_дневникhttp://opencarbon.ru/участники:коля:читательский_дневник TODO: переделать в отдельные статьи

# Курс лекций "Алгоритмы во внешней памяти". Максим Бабенко

[http://www.youtube.com/embed/KsPv6X9ysqI](http://www.youtube.com/embed/KsPv6X9ysqI) [http://www.lektorium.tv/lecture/13929](http://www.lektorium.tv/lecture/13929)

На курсе рассказывают про алгоритмы, которые работают с данными, которые, по тем или иным причинам, не могут поместиться в оперативную память (когда файлы лежат на HDD/SSD или, например, в хадупе на HDFS). Объясняется сложность таких алгоритмов, относительно количества дисковых операций, теория подана довольно просто и интуитивно, мозг хорошо настраивается на мысль, что не так важна производительность кода, когда доступ к данным такой дорогой.

На 3-4й лекции завтыкал, примеры про алгоритмы на графах мне не очень близки. Может, почитаю про эти алгоритмы в памяти и пересмотрю как все меняется, когда граф окажется очень большим. Но первые лекции очень хороши.

В последней [лекции](http://www.youtube.com/embed/uCfgk1sx_Pg) акцент смещают с внешней памяти и оперативной на CPU-кеш и оперативную память. Скорости тут, конечно, будут другие, но порядок, на который отличается скорость доступа к кешу и ОЗУ, и порядок ОЗУ и HDD примерно одинаков, на мой взгляд. 5 лекция будет сама по себе полезна, если тебе нужен быстрый алгоритм, который работает с данными в ОЗУ. Минимизация доступа к ОЗУ сможет дать большой прирост производительности, да и круто это, знать как работает кеш в CPU :)

Вместо пятой лекции, конечно, советую прочитать "What Every Programmer Should Know About Memory" [https://www.akkadia.org/drepper/cpumemory.pdf](https://www.akkadia.org/drepper/cpumemory.pdf) , но там много, и мне плохо зашли части про бечмаркинг скорости, т.к. нет под рукой проекта, на который я могу примерять цифры, чтобы их осознавать.

# Курс лекций "Методы и системы обработки больших данных". Иван Пузыревский

[http://www.youtube.com/embed/IHVIFVZeXcA](http://www.youtube.com/embed/IHVIFVZeXcA) [http://www.lektorium.tv/lecture/30079](http://www.lektorium.tv/lecture/30079)

[http://compsciclub.ru/courses/bigdatasystems/2017-spring/](http://compsciclub.ru/courses/bigdatasystems/2017-spring/)

Очень качественный и свежий курс про распределенные системы, про их работу под капотом. Речь идет про системы хранения, очереди и БД: HDFS, HBase, Cassandra, Kafka; про MapReduce и системы потоковой обработки: Hadoop MapReduce, Spark, Storm, Spark Streaming, плюс две лекции про Zookeeper и одна про Hive.

Внешнее API систем и примеры использования приведены в основном для общего понимания, основная часть сосредоточена на внутренней архитектуре систем. Очень полезно для определения применимости этих систем в ваших проектах, поможет самостоятельно прикидывать производительность при применении той или иной технологии.

На лекциях разбирается архитектура, строение и алгоритмы, на которых основываются системы. Начинается все с HDFS из хадуповского стека, который является базовым строительным блоком распределенной системы на базе hadoop, на его примере также разбирается работа и деплой кода в hadoop YARN.

Довольно забавно было, когда после первой лекции про HDFS была полная уверенность в том, что оно точно не подходит для БД, а в 3й лекции рассказывают про быстрый и производительный HBase, который хранит свои данные в HDFS и делает это консистентно.

В лекциях было очень мало информации про свежие фичи данных систем, про интересное API, примеры производительных интеграций. Сложилось такое ощущение, что какой-нибудь MapReduce с помощью твиков можно разогнать на пару порядков (Spark как раз один из известных твиков, хе-хе). Но тогда можно было бы ожидать по 11 лекций на каждую систему, вместо одной, да и цель курса немного не про это. Тема API и применимости также рассматривается в хорошей книге [Семь баз данных за семь недель](http://dmkpress.com/catalog/computer/databases/978-5-94074-866-3/), основной плюс которой в ее компактности, так что материал там изложен довольно сумбурно.

В общем, если вы вечно путаете все эти модные словечки из темы MapReduce, не можете запомнить чем отличается Spark и Storm, Spark/HBase/Riak - после просмотра лекций у вас надолго в голове останутся "крючки", за которые в будущем можно будет легко сориентироваться в этом зоопарке.

P.S. нужно будет пересмотреть [Яндекс изнутри: инфраструктура хранения и обработки данных](https://www.youtube.com/watch?v=9ANuWEZqCUg), что на самом деле в тренде. P.P.S. [Как устроен поиск Яндекса: о чём невозможно прочитать](https://www.youtube.com/watch?v=BCVsgup8hUQ) - тоже прикольный видос, давно смотрел, уже не помню про что там.

# Машинное обучение

[Семинар по глубокому обучению или как стать Data Scientist’ом ](https://​www.youtube.com/​watch?​v=mk6CCruAxHg)

Несложная,​ поверхностная лекция по теме машинного обучения,​ описние простых нейронных сетей, использования сверток и пулинга. Некоторые темы предполагаются,​ как уже знакомые зрителю,​ но это мешает только в паре мест доклада. В конце показывается пример на python+ TensorFlow по построению и обучению нейросети для определения цифр.

[Практическое занятие по обработке текста в gensim с помощью алгоритма word2vec](https://www.youtube.com/watch?v=U0LOSHY7U5Q)

Слабый докладчик IMHO. Реальные кейсы не знает, на вопросы отвечает не прямо.

Полу-лекция, полу-доклад про алгоритмы категоризации для слов. Из плюсов, что в комплекте идет IPython notebook с кодом и можно вместе с лектором ручками по-запускать все самому. Но из-за практической составляющей в видео очень много пауз, плюс многое оставлено вне доклада (вы можете что-то запустить, но как оно работает, может остаться для вас непонятным). Так себе, в общем, не советую без параллельной практики.

Если у вас 500млн слов текста, word2vec - ок, doc2vec лучше от 1млн (будет гуд).

# Бизнес

Ларри Боссиди и Рэм Чаран [Исполнение](https://www.ozon.ru/context/detail/id/5943887/)

В книге рассказывается про построение так называемой «культуры исполнения»:\\
- мотивация руководства работать на результат\\
- выстраивание контроля над выполнением планов на всей иерархии сотрудников\\
- взаимопомощь, наставничество, выращивание кадров, правильная расстановка кадров\\
- ответственность за взятые на себя обязательства, бесконечная работа над совершенствованием себя и бизнеса\\
- открытый диалог между всеми сотрудниками, особый упор на высказывание всех своих мыслей и откровенный разговор, обнажение всех проблем на совещаниях для построения реалистичных планов и прогнозов; но не забывать про общение с рядовыми сотрудниками тоже, часто они могут о многом сказать, а ваша открытость и прозрачность политики предприятия снизит накал волнения у них\\
- движение в сторону больше мобильности: сокращение запасов, большая открытость перед продавцами и поставщиками, быстрая корректировка планов и направления развития при внешних изменениях и разработка планов с учетом непредвиденных обстоятельств и невыполнения некоторых его пунктов\\
- выставление крайне оптимистичных, но выполнимых планов; поддержание всего бизнеса в тонусе и нацеливание на постоянный рост показателей\\
- повторюсь, но на это делается большой акцент: планы ставятся крупные, но они разрабатываются и потом согласовываются с непосредственными исполнителями, выясняются стратегии в случае невыполнения планов и оглашается список методов, с помощью которых эти планы планируется выполнить\\
- методы выполнения планов, вкупе с контролем выполнения приводит к разбиению большого плана компании на более мелкие контрольные точки/задачи, которые проще контролировать, которые ведут к результату постепенно, что позволяет, в свою очередь, быстро подстраиваться под ситуацию и разворачивать курс на 180 градусов\\
- поддержание производственного плана (цели в показателях, задачи) и стратегического плана (новые перспективы, планирование на будущее, вектор компании) в синхронизированном состоянии, ориентация на завтрашний день; задачи решаются более «позитивно», если исполнитель видит причины возникновения этой задачи и ее более глобальные результаты в стратегическом плане\\
- перемена оценки работы отделов от сравнения с прошлыми показателями к соответствию будущим, запланированным показателям, показателям конкурентов\\
- планы и действия обязательно сверяются с положением конкурентов, рынка и собственных кадров и возможностей фирмы; не стоит развивать новую технологию из смежной области, если у вас нет подходящих кадров, кому это под силу; не стоит открывать завод в азии, если нет человека, понимающего тамошнюю обстановку, тех людей, их законы и особенности, ну и политическую обстановку, конечно

В общем, компания должна быть мобильна, контролируема, прозрачна, желающая совершенствоваться в каждом конкретном сотруднике, с выстроенной и справедливой системой мотивации.

Книга все же рассчитана, как и сказано на обложке книги, больше рассчитана на руководящий состав, чем на обычного читателя, из-за этого книга читается не очень приятно, хотя все разжевано и понятно, наблюдается какая-то затянутость и нудность особенно в раскрытии всяких известных (для людей, на которых нацелена книга) топ-менеджеров.

Но и далекому от этого человеку книга позволит взглянуть на постоянно меняющуюся бюрократию фирмы, в которой он работает, по-новому. Более лояльно, как минимум, а то и принять в этом более активное участие.

Обсуждая некоторые моменты из этой книги (а многое в ней актуализировано на 2001 год), высказываются мнения, что очень многое в ней уже устарело. А мое впечатление о том, что книга призывает руководящих лиц «спускаться на ступень ниже», узнавать как можно больше о людях в своем подчинении, в их подчинении, о нюансах своего продукта, его производства, продаж, маркетинга, найма и воспитания кадров и прочего - это миф, и признак плохого руководителя. В книге делается большой упор на помощь высших директоров своим подчиненным в их непосредственной деятельности советами, давать которые, без глубокого погружения, бессмысленно, на мой взгляд. Но будем разбираться дальше, время покажет.

# PostgreSQL

Курс "Hacking PostgreSQL" Анастасия Лубенникова [Postgres Professional](https://postgrespro.ru/education/courses/hacking) [YouTube](https://www.youtube.com/playlist?list=PLaFqU3KCWw6Jfb8IBNk3hZ07dxMxjfGtv)

Курс от Postgres Professional по особенностям архитектуры и внутреннего устройства PostgreSQL. Курс (на данный момент из 8 лекций) был встречен мной амбициозно, ждал его с нетерпением. Но он мне «не зашел». Не сказать, что разочаровал, но я не смог придумать аудиторию, на кого это было рассчитано. В лекциях (примерно с 4й по 7) рассказывают про внутренние исходники бекенда, какие функции где и как используются. Не дается ни исторической справки о причинах данного подхода, о его плюсах/минусах. Озвучиваются известные, в сообществе разработчиков Postgresql, узкие места и проблемы в отдельных местах кода. Для меня, как для интересующегося, но напрямую не имеющего отношения к разработке Postgresql человека, это оказалось слишком нудно и сильно бесполезно. Знание о внутренней архитектуре залито большой кучей названий функций и структур. Думаю, этот курс подойдет для людей, кто уже провел достаточно времени за разработкой модулей для Postgresql, для того, чтобы сверить свои догадки с реальностью и использовать все возможности, которые доступны внутри кодовой базы (хотя есть вероятность, что из само кода, документации и комментариев это можно сделать гораздо продуктивнее). Остальным не советую.

8ю лекцию я еще не осилил, но выглядит интересно, со стороны обзора реализации работы с планами и запросами на языке си. TODO

Конечно, стоит отметить, что из лекций можно подчерпнуть много полезной информации: об архитектуре всей системы (из 1й лекции), об сообществе (как сделать патч, чтобы его приняли в первой(?) части 2й лекции), в 3й и, кажется, 4й лекции были примеры разработки готового модуля расширения для БД и расширения запроса CREATE TABLE с добавлением нового ключевого слова. Было много кишков с описанием, как это влияет на тюнинг системы. Но меня не покидало чувство, что всю эту информацию и уже слышал из статей по тюнингу и обзора кишков там было не меньше, но по объему и качеству там было намного лучше.

# Python

Продвинутое использование py test Андрей Светлов [YouTube](https://www.youtube.com/watch?v=7KgihdKTWY4)

Перед выбором фреймворка для тестирования python-приложений - обязательно к просмотру! В докладе рассказано как применять pytest, базовые основы, которые плавно переходят в интересные продвинутые особенности современных тестовых фреймворков с привязкой к реальным потребностям. Рассказано все живо, смотреть приятно, мотивирующий эффект остается надолго. Что еще сказать - не знаю, смотрел давно, буду пересматривать.

P.S. Важной особенностью самого pytest и аналогов я считаю, что его очень легко внедрить в текущую инфраструктуру тестов вашего проекта, оно не несет с собой большой и сложной инфраструктурной нагрузки, не требует долгого обучения. Но просмотр одного только этого доклада даст вам множество идей по улучшению ваших тестов, сокращению строк кода и повышения их читабельности.

Иван Цыганов (Positive Technologies) - Почему 100 % покрытие это плохо [YouTube](https://www.youtube.com/watch?v=Y8CK6AMqskQ)

Интересный доклад про нюансы текущей реализации coverage.py для подсчета покрытия и как его можно улучшить. В докладе кратко описан базовый паттерн работы с байт-кодом python (его использует, например, PonyORM, если не путаю) и работа с байт-кодом.

Доклад я бы рассматривал как light-talk про питон, coverage и байткод. Полезного не много, зато интересно.

# Заметки по неинформированному поиску

[википедия](https://ru.wikipedia.org/wiki/Алгоритм_соединения_слиянием_сортированных_списков)

Читал толстенную книгу [Искусственный интеллект. Современный подход](https://www.goodreads.com/book/show/9649159) и, в который раз читая про типовые алгоритмы поиска, решил записать какие полезные мысли они вызывают в моей голове.

С поиском в ширину и в глубину все знакомы. Первый ест память, разворачивая у себя в голове все дерево, которое он обходит. Второй может может долго и глубоко искать решение, которое может быть совсем рядом с вершиной графа, а то и вовсе зациклиться.

В коде приложений часто встречаются рекурсивный код, напоминающий поиск в глубину по своей структуре. Либо прямо, когда объекты ссылаются на себе подобных, образуя граф, либо косвенно, ссылающихся на другие объекты, которые имеют обратные ссылки. В результате могут образовываться невычислимые циклы разной сложности. Часто возможно заранее определить примерную глубину рекурсии и важно всегда вводить лимит глубины рекурсии, чему нас учит «поиск с ограничением глубины» Вероятно, стоит сразу вводить это ограничение, когда становится известно, что в алгоритме возможны циклы, в противном случае приложение может даже не выводить ошибок, а просто зависать намертво.

Сложив вместе устойчивость к циклам, поиск узлов в порядке углубления в граф поиска в ширину и потребление памяти поиска в глубину, можно получить «поиск в глубину с итеративным углублением». Он работает, перезапуская «поиск с ограничением глубины», увеличивая, каждый раз, глубину поиска. Так как он не хранит уже обсчитанные узлы, выглядит он очень расточительным. Поинт в том, что если граф поиска расширяется пропорционально высоте, то сложность этого алгоритма не сильно отличается от поиска в ширину, сохраняя при этом экономичность по памяти. Взять, например, поиск по файловой системе. Если хочется искать, проходя от уровня к уровню, но писать структуры для хранения такого большого состояния поиска в ширину и код его обхода не хочется - можно перезапускать поиск в глубину с лимитом каждого уровня: код получится простой, поиск полным, а памяти будет затрачено мало. Я не предлагаю использовать данный метод для поиска в ФС, для этого наверняка есть специальные алгоритмы и многое зависит от факторов: если потребуется поиск по содержимому файлов, каждое действие станет слишком дорогим, чтобы повторять его на каждой итерации. Но если речь идет только о именах файлов, а таблица файлов ФС помещается в кеш оперативной памяти - вероятно, в пропорции скорость/простота/качество это будет хорошим вариантом.

Оставшиеся поиски по критерию стоимости и двунаправленный поиск достаточно специфичны, чтобы как-то обобщить их на повседневную работу с кодом. Хотя аналогом двунаправленного поиска (с ручным управлением) можно считать операцию join, знакомую всем по реляционным БД. Одинарные join могут быть тривиальными, но для решения множественных join нескольких таблиц, движок реляционной БД может, на основании своих знаний о «графе» (приблизительные размеры таблиц, условия фильтрации, объем оперативной памяти), выбрать места склеивания таблиц и порядок склеивания, чтобы результирующий подграф поиска был минимальным. И хоть такие сложные вещи, как executor запросов в БД, редко приходится писать, бывает полезно искать пути поиска решения с разных сторон. Например, при расчете начисления абон.платы пользователям, заранее загрузить в кеш все тарифы и вычислить их сумму, если это возможно, а не делать это каждый раз. Это же касается замены кучи запросов к БД при генерации страницы в каком-нибудь веб фреймворке одним большим запросом. Не делайте кучи подзапросов…

# LDAP

[LDAP для учёных-ракетчиков](https://pro-ldap.ru/tr/zytrax/)

Очень хорошее описание технологии LPAD и ее корней с нуля. Повествование ведется с основ, но не затянуто, в итоге было прочитано за одну ночь. Имеет как общее описание технологии, так и описание ее реализаций, примеры идут на OpenLDAP.

На мой взгляд, не раскрыт момент авторизации клиентов и соответствующие технологии. Плюс в книге мало реальных примеров использования LDAP. Поверх LDAP можно сделать очень много разных вещей, и описание самой технологии оценивается как верхушка большого пласта полезной информации. Это как изучить ЯП и не написать ни одного полноценного проекта.

Но при всем при этом, книга отлично подходит для тех, кто хочет раз и навсегда досконально разобраться что за зверь такой LDAP.

# Алгоритмы

Как сделать в конкурентном контейнере невозможные вещи — итераторы — Максим Хижинский [|YouTube](https://www.youtube.com/watch?v=qeS322ymI5o)

Отличный доклад для тех, кто любит поразминать мозги алгоритмами. В докладе дано краткое введение в lock-free алгоритмы и пример реальной задачи, которую не так просто реализовать на практике, как может показаться на первый взгляд.

В докладе "всковырнут" целый ворох интересных принципов в построении алгоритмов, я бы рассказал по-подробнее, но смотрел давно и уже все забыл. Как-нибудь обязательно пересмотрю этот доклад.

# Генетика, биохимия, биоинформатика

История исследования ДНК и белковых структур | Алексей Шпильман [Лекция 1](https://www.youtube.com/watch?v=lRkLZ01s-Fw) [ Лекция 2](https://www.youtube.com/watch?v=2wgWquZWZJw)

Быстрый, немного скомканный, исторический экскурс к истокам науки биоинформатики. Самой биоинформатики, как ни странно, в лекциях нет (возможно, будет 3я лекция).

В первой части описывается история химических открытий. Автор попытался уместить весь необходимый материал в одну лекцию, в итоге неподготовленный зритель, вроде меня, не успеет отложить все это в голове, но это, безусловно, интересно.

Во второй части идет рассказ исключительно про историю развития генетики. Знакомый с эти лишь освежит фамилии и принципы в памяти, а для незнакомого, опять же, слишком все сжато.

Про историю генетики, если есть время, лучше прочитать в книге Геном: автобиография вида в 23 главах [отзыв ](https://www.goodreads.com/review/show/2097411906)

[Все, что вы хотели знать про молекулярную биологию, но не удосужились спросить Михаил Гельфанд](https://www.youtube.com/watch?v=UJyVLZWhMLI)

# Дизайн

[Круглее круга: оптические эффекты при проектировании интерфейсов](https://habrahabr.ru/post/338780/)

В статье описываются несколько дизайнерских трюков и приемов, которые встречаются, наверное, во всех местах с электронным интерфейсом: веб, интерфейсы ОС, иконки, текст, шрифты.

Проясняются моменты, связанные с тем, что выверенные до пикселя рамки верстки вдруг кажутся кривыми и убогими. Дается описание приемов, как это можно устранить, уходя от геометрически-выверенных расчетов.

# Vim

Шикарный коммент  со [Stack Overflow](https://stackoverflow.com/questions/1218390/what-is-your-most-productive-shortcut-with-vim/1220118#1220118).
После него очень хочется таки начать пользоваться vim'ом. Особенно порадовало погружение в историю, например, что grep появился как команда :g/re/p в ex. Часто, через понимание истории проще запоминать и понимать какие-либо команды и процессы.

TODO: выписать полезности из комментария, короткий список того, чем можно начать пользоваться.</textarea><div id='targetDiv'></div>
    <script>
  var text = document.getElementById('sourceTA').value,
      target = document.getElementById('targetDiv'),
      converter = new showdown.Converter(),
      html = converter.makeHtml(text);

    target.innerHTML = html;
</script>
</body>
</html>
