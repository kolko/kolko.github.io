Приручаем bash-евый flock
=========================

 Рано или поздно приходит осознание того, что, запустив параллельно несколько 
версий вашего скрипта, будет нанесено больше вреда, чем пользы. Самое время 
задуматься про использование блокировки повторного запуска. 

 Статью постараюсь вести в формате эволюции приемов, которые довелось применять
в собственной практике и видеть в коде коллег, рассматривать плюсы и минусы.
А в конце приведу решение, которое кажется самым близким к идеальному, но
и оно содержит достаточное количество проблем.


### 1. Bash? Конечно же файлы!

 Почему бы нам при старте не создавать файл, оповещающий о том, что мы уже 
запущены? Действительно, это очень просто!

```bash
main() {
    lockfile="/tmp/already_running.lock"
    if [ -f "$lockfile" ]; then
        echo "Already running!"
        exit 1
    fi
    touch "$lockfile"
    # ... do a good stuff
    rm -f "$lockfile"
}
```

 Все работает. А что если кто-то нажмет Ctrl+c или скрипт упадет? Для этого
есть trap.

```bash
_exit(){
	rm -f "$lockfile"
}
trap _exit EXIT
```

 Все круто, но когда количество пользователей вашего скрипта растет, вам 
все чаще приходится вручную удалять этот файл. Возможно, это был kill -9
или ресет компьютера, файл на месте. Идем на хитрость (хотя кто-то кинет
в меня тапком и скажет, что это стандарт), записываем свой pid в lock-файл
и проверяем, а существует ли этот процесс?

```bash
main() {
    lockfile="/tmp/already_running.lock"
    if [ -f "$lockfile" ] && [ -d /proc/"$(<$lockfile)" ]; then
        echo "Already running!"
        exit 1
    fi
    echo "$$" > "$lockfile"
    # ... do a good stuff
    rm -f "$lockfile"
}
```

 Но что, если под этим pid'ом уже работает другой процесс? Это можно проверить.
Также, можно класть lock-файлы не в /tmp, а в другой каталог, который будет
очищаться при каждой загрузке системы для помощи при ресетах и служить гарантией,
что в самой паршивой ситуации перезагрузка спасет работу сервера (и ваш выходной).

 Видя количество кода, каждая строчка которого "подпирает" предыдущую, чувство
долга заставляет искать альтернативные варианты. Действительно, в других
языках ни кто не стал бы создавать файлы и обвешивать логикой, там первым
в голову приходит понятие блокировок. Гуглим, для bash есть замечательная
утилита flock. И программист уже находится в шаге от крупного рефакторинга... :)

> Варианты с файлом, на самом деле, достаточно хороши. Масса примеров в гугле
>только подтверждают это. Даже без сильно сложных костылей (например анализа 
>процесса, запущенного под pid из lock-файла). Для рядовых скриптов это обеспечит
>надежность на уровне 95%. И такой код я бы не стал считать "дурно пахнущим"
>или кандидатом на рефакторинг. Тем более, в нем сможет разобраться любой
>программист с начальным знанием bash.

### 2. Привет, flock!

 Для начала, разберемся с параметрами:

```
flock [-sxon] [-w timeout] lockfile [-c] command...
flock [-sxon] [-w timeout] lockdir [-c] command...
flock [-sxun] [-w timeout] fd 
```

 Считая lockdir и lockfile одинаковыми вещами, получаем, что flock может
применяться для блокирования по файловому дескриптору (открытого с помощью 
команды exec) либо по имени файла. Но при блокировании по имени, flock вызывает
внешнюю команду, что нам не подходит, т.к. функции bash скрипта он вызывать
отказывается (на самом деле не все так однозначно).

 По аргументам, нам нужны:
    -x - для эксклюзивной блокировки
    -n - чтобы не ждать, пока предыдущий экземпляр отпустит блокировку, а сразу
оповещать, что приложение уже запущено

 Понеслась!

```bash
main() {
    (
        if ! flock -xn 200; then
            echo "Already running!"
            exit 1
        fi
        # ... do a good stuff
        
    ) 200>/var/lock/already_running.lock
}
```

 Супер! Все работает! Но вдруг через неделю-две обнаруживается, что скрипт
перестал запускаться: "Already running!",- говорит, но по ps aux процесс
не видно. Странно.

 После нескольких попыток (не считая случаев, когда вы случайно теряете ситуацию
и ждете еще пару недель в ожидании повтора) вы обнаруживаете засранца:

```bash
for prog in /proc/*/fd/; do echo "$prog"; ll "$prog"; done | grep -B 10 --color 'already_running.lock'
```

 Внезапно, ловите процесс cron (или любой другой, это не важно, может даже
несколько). Как?

### 3. Говорили мне, не юзай flock!

 Дело в том, что bash не закрывает свои дескрипторы перед форком и exec'ом
запускаемых им приложений. И дескриптор, с открытым на него локом, утекает
в другие приложения. Например, если ваш скрипт запускает /etc/init.d/crond restart,
то crond с радостью возьмет ваш lock на сохранение и ваш скрипт уже никогда
не запустится.

 Но проблема решаема. Всего лишь нужно пристальней приглядывать за вызовами
внешних программ, не отдавая им дескриптор. А в trap'е можно снимать лок
с дескриптора и вообще лок-файл удалять. Вот только нужно будет понять, что
мы в trap попали не после ошибки взятия лока... 

```bash
lockfile="/tmp/already_running.lock"
_exit(){
	rm -f "$lockfile"
}

main() {
    exec 200>$lockfile
    if ! flock -xn 200; then
        echo "Already running!"
        exit 1
    fi
    # Теперь можно и trap повесить
    trap _exit EXIT
    
    # ... do a good stuff
    
    # А перед вызовом crond, закроем дескриптор, чтобы не утек!
    exec 200<&-
    /etc/init.d/crond restart
}
```

> Кек
> run_extern() { ( exec 200<&-; $@; ) }
> run_extern /etc/init.d/crond restart

### 4. А вариант с файлами без блокировок был не так уж плох...

 Конечно, можно все засунуть в удобные библиотечные функции, но уровень
удобства недотягивает до других языков. Да и напряженность из-за возможностей
прострелить себе ногу, забыв что-то удалить, не покидает.

 И перед глазами маячит флаг -o, который позволяет закрыть абстракцию с блокировкой
на уровне самого flock, но чтобы его использовать нам нужно всегда писать
два скрипта, один из которых будет заниматься запуском второго с помощью flock.
Неудобно, да и в библиотеку это не скрыть. Или скрыть?

bash_with_lock
```bash
#!/usr/bin/env bash
set -eu

lockfile="$1"

flock -x -n -o $lockfile -c "/bin/bash $*" || ret=$?
#if [ "$ret" == "1" ]; then
#    echo "File $1 already running!"
#    exit 1
#fi
exit "$ret"
```

script.sh
```bash
#!./bash_with_lock

# ... do a good stuff
```

 С помощью этого маленького скрипта bash_with_lock можно исключить параллельный
запуск вашего скрипта, просто прописав его в shebang! И больше никаких утечек
дескрипторов.

 Из проблем, вы не сможете повешать свой код обработки ситуации, когда скрипт
уже запущен (например, прибить его, если он запущен уже больше часа). Да
и в самом файле bash_with_lock не совсем понятно, код возврата 1 вернул сам flock
или команда, которую он запустил.

 Изначально, я брал лок на отдельный файл в /tmp/, но потом мне подсказали,
что в unix чуть ли не стандарт, что для блокировки повторного запуска нужно
брать блокировку на сам исполняемый файл (как и сделано в примере). И получил
неожиданную реакцию bash, который отказывался запускать файл script.sh,
когда тот был под блокировкой. Т.е. закомментированная ветвь в bash_with_lock
вообще никогда не выполнится из-за flock. Стандартное ли это поведение,
или просто случайно сошлось, что bash блокирует файл на время его чтения в
память - мне не известно, когда руки дойдут - надеюсь, получится еще пара
глав для статьи.